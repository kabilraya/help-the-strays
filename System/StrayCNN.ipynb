{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1579991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7373977e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10db3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../Dataset/Image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d29749fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50286aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50655 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "022d7865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12662 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739f887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fa0aef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\royka\\anaconda3\\envs\\deeplearn\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "        # First Conv Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128,128, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second Conv Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third Conv Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Fourth Conv Block\n",
    "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Classifier\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b206290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac8131d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy','precision','recall'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dadea31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9216</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9216\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m4,719,104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,243,073</span> (20.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,243,073\u001b[0m (20.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,241,089</span> (19.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,241,089\u001b[0m (19.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> (7.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,984\u001b[0m (7.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8cadee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55bc613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1272s\u001b[0m 803ms/step - accuracy: 0.7398 - loss: 0.5796 - precision: 0.7410 - recall: 0.7391 - val_accuracy: 0.6987 - val_loss: 0.6098 - val_precision: 0.6678 - val_recall: 0.8023\n",
      "Epoch 2/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1243s\u001b[0m 786ms/step - accuracy: 0.8482 - loss: 0.3582 - precision: 0.8428 - recall: 0.8587 - val_accuracy: 0.7102 - val_loss: 0.7139 - val_precision: 0.8984 - val_recall: 0.4801\n",
      "Epoch 3/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1188s\u001b[0m 751ms/step - accuracy: 0.8749 - loss: 0.3095 - precision: 0.8724 - recall: 0.8801 - val_accuracy: 0.7534 - val_loss: 0.6115 - val_precision: 0.9321 - val_recall: 0.5516\n",
      "Epoch 4/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1269s\u001b[0m 802ms/step - accuracy: 0.8924 - loss: 0.2682 - precision: 0.8902 - recall: 0.9006 - val_accuracy: 0.8039 - val_loss: 0.5292 - val_precision: 0.8686 - val_recall: 0.7206\n",
      "Epoch 5/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1251s\u001b[0m 790ms/step - accuracy: 0.9029 - loss: 0.2474 - precision: 0.8998 - recall: 0.9096 - val_accuracy: 0.6681 - val_loss: 0.8689 - val_precision: 0.9419 - val_recall: 0.3650\n",
      "Epoch 6/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 798ms/step - accuracy: 0.9104 - loss: 0.2339 - precision: 0.9056 - recall: 0.9176 - val_accuracy: 0.7909 - val_loss: 0.4703 - val_precision: 0.8558 - val_recall: 0.7046\n",
      "Epoch 7/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1210s\u001b[0m 764ms/step - accuracy: 0.9124 - loss: 0.2251 - precision: 0.9076 - recall: 0.9193 - val_accuracy: 0.8146 - val_loss: 0.4255 - val_precision: 0.8754 - val_recall: 0.7376\n",
      "Epoch 8/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1240s\u001b[0m 784ms/step - accuracy: 0.9177 - loss: 0.2202 - precision: 0.9135 - recall: 0.9245 - val_accuracy: 0.6327 - val_loss: 1.2681 - val_precision: 0.9759 - val_recall: 0.2793\n",
      "Epoch 9/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1267s\u001b[0m 800ms/step - accuracy: 0.9221 - loss: 0.2051 - precision: 0.9178 - recall: 0.9290 - val_accuracy: 0.8646 - val_loss: 0.3568 - val_precision: 0.9296 - val_recall: 0.7916\n",
      "Epoch 10/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1401s\u001b[0m 885ms/step - accuracy: 0.9251 - loss: 0.1981 - precision: 0.9191 - recall: 0.9333 - val_accuracy: 0.6353 - val_loss: 1.3086 - val_precision: 0.5807 - val_recall: 0.9981\n",
      "Epoch 11/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1381s\u001b[0m 872ms/step - accuracy: 0.9291 - loss: 0.1888 - precision: 0.9258 - recall: 0.9337 - val_accuracy: 0.7015 - val_loss: 1.0679 - val_precision: 0.9787 - val_recall: 0.4177\n",
      "Epoch 12/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1417s\u001b[0m 895ms/step - accuracy: 0.9299 - loss: 0.1874 - precision: 0.9285 - recall: 0.9331 - val_accuracy: 0.8561 - val_loss: 0.3757 - val_precision: 0.9470 - val_recall: 0.7574\n",
      "Epoch 13/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1339s\u001b[0m 846ms/step - accuracy: 0.9331 - loss: 0.1812 - precision: 0.9280 - recall: 0.9400 - val_accuracy: 0.8649 - val_loss: 0.3846 - val_precision: 0.9081 - val_recall: 0.8148\n",
      "Epoch 14/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1370s\u001b[0m 865ms/step - accuracy: 0.9331 - loss: 0.1800 - precision: 0.9300 - recall: 0.9386 - val_accuracy: 0.8523 - val_loss: 0.3487 - val_precision: 0.8596 - val_recall: 0.8456\n",
      "Epoch 15/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1221s\u001b[0m 771ms/step - accuracy: 0.9356 - loss: 0.1758 - precision: 0.9308 - recall: 0.9427 - val_accuracy: 0.7924 - val_loss: 0.5431 - val_precision: 0.9629 - val_recall: 0.6123\n",
      "Epoch 16/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1207s\u001b[0m 762ms/step - accuracy: 0.9389 - loss: 0.1663 - precision: 0.9352 - recall: 0.9440 - val_accuracy: 0.8151 - val_loss: 0.5564 - val_precision: 0.9081 - val_recall: 0.7051\n",
      "Epoch 17/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1218s\u001b[0m 769ms/step - accuracy: 0.9358 - loss: 0.1715 - precision: 0.9322 - recall: 0.9420 - val_accuracy: 0.8914 - val_loss: 0.2846 - val_precision: 0.9128 - val_recall: 0.8678\n",
      "Epoch 18/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1262s\u001b[0m 797ms/step - accuracy: 0.9412 - loss: 0.1601 - precision: 0.9380 - recall: 0.9458 - val_accuracy: 0.8458 - val_loss: 0.5066 - val_precision: 0.7832 - val_recall: 0.9604\n",
      "Epoch 19/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1335s\u001b[0m 843ms/step - accuracy: 0.9429 - loss: 0.1582 - precision: 0.9394 - recall: 0.9481 - val_accuracy: 0.8627 - val_loss: 0.3314 - val_precision: 0.9193 - val_recall: 0.7982\n",
      "Epoch 20/20\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1376s\u001b[0m 869ms/step - accuracy: 0.9428 - loss: 0.1574 - precision: 0.9392 - recall: 0.9486 - val_accuracy: 0.8815 - val_loss: 0.3093 - val_precision: 0.9523 - val_recall: 0.8055\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1dfbc898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"animals_vs_nonanimals_cnn_three.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8cf40d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ae02065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 279ms/step - accuracy: 0.8822 - loss: 0.3013 - precision: 0.9547 - recall: 0.8069\n",
      "\n",
      "Validation Accuracy: 0.8827\n",
      "Validation Precision: 0.9526\n",
      "Validation Recall: 0.8079\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy, val_precision, val_recall = model.evaluate(val_generator)\n",
    "print(f\"\\nValidation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {val_precision:.4f}\")\n",
    "print(f\"Validation Recall: {val_recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d411be96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 178ms/step\n"
     ]
    }
   ],
   "source": [
    "val_generator.reset()\n",
    "y_pred_probs = model.predict(val_generator)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "y_true = val_generator.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7feef4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45fe5190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics of the model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Animals       0.50      0.57      0.53      6270\n",
      " Non-Animals       0.51      0.43      0.47      6392\n",
      "\n",
      "    accuracy                           0.50     12662\n",
      "   macro avg       0.50      0.50      0.50     12662\n",
      "weighted avg       0.50      0.50      0.50     12662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics of the model\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Animals', 'Non-Animals']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e8f8d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[3597 2673]\n",
      " [3641 2751]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb77c05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import Label, Button\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "\n",
    "model = load_model(\"animals_vs_nonanimals_cnn.h5\")\n",
    "\n",
    "\n",
    "def predict_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img_resized = cv2.resize(img, (128, 128))\n",
    "    img_array = img_resized.astype(\"float32\") / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0][0]\n",
    "    return \"Animal\" if prediction <= 0.5 else \"Non-Animal\"\n",
    "\n",
    "\n",
    "def upload_file():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "    if file_path:\n",
    "        \n",
    "        label = predict_image(file_path)\n",
    "        \n",
    "        \n",
    "        img = Image.open(file_path)\n",
    "        img = img.resize((300, 300)) \n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        panel.config(image=img_tk)\n",
    "        panel.image = img_tk\n",
    "        \n",
    "        \n",
    "        result_label.config(text=f\"Prediction: {label}\", fg=\"green\", font=(\"Arial\", 16, \"bold\"))\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Animal vs Non-Animal Classifier\")\n",
    "root.geometry(\"400x450\")\n",
    "\n",
    "\n",
    "upload_btn = Button(root, text=\"Upload Image\", command=upload_file, font=(\"Arial\", 14), bg=\"lightblue\")\n",
    "upload_btn.pack(pady=10)\n",
    "\n",
    "\n",
    "panel = Label(root)\n",
    "panel.pack()\n",
    "\n",
    "\n",
    "result_label = Label(root, text=\"\", font=(\"Arial\", 14))\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c796376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "Counter({np.int32(1): 6392, np.int32(0): 6270})\n",
      "Total samples: 12662\n",
      "Animals: 6270\n",
      "Non-Animals: 6392\n"
     ]
    }
   ],
   "source": [
    "# Check your data distribution\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(Counter(y_true))\n",
    "\n",
    "# Check if there's data leakage or wrong labels\n",
    "print(f\"Total samples: {len(y_true)}\")\n",
    "print(f\"Animals: {sum(y_true == 0)}\")\n",
    "print(f\"Non-Animals: {sum(y_true == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f0091",
   "metadata": {},
   "source": [
    "## USING A PRETRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6bb14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e597fa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', \n",
    "                        include_top=False, \n",
    "                        input_shape=(128, 128, 3))\n",
    "base_model.trainable = False  \n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3218e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41c641e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m771s\u001b[0m 485ms/step - accuracy: 0.9455 - loss: 0.1509 - val_accuracy: 0.9624 - val_loss: 0.1147 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m782s\u001b[0m 494ms/step - accuracy: 0.9729 - loss: 0.0799 - val_accuracy: 0.9603 - val_loss: 0.1111 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m778s\u001b[0m 491ms/step - accuracy: 0.9741 - loss: 0.0767 - val_accuracy: 0.9629 - val_loss: 0.1103 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m801s\u001b[0m 506ms/step - accuracy: 0.9774 - loss: 0.0705 - val_accuracy: 0.9703 - val_loss: 0.0940 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m821s\u001b[0m 519ms/step - accuracy: 0.9791 - loss: 0.0641 - val_accuracy: 0.9750 - val_loss: 0.0849 - learning_rate: 0.0010\n",
      "Epoch 6/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m778s\u001b[0m 491ms/step - accuracy: 0.9780 - loss: 0.0638 - val_accuracy: 0.9744 - val_loss: 0.0853 - learning_rate: 0.0010\n",
      "Epoch 7/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m757s\u001b[0m 479ms/step - accuracy: 0.9798 - loss: 0.0612 - val_accuracy: 0.9759 - val_loss: 0.0771 - learning_rate: 0.0010\n",
      "Epoch 8/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m766s\u001b[0m 484ms/step - accuracy: 0.9796 - loss: 0.0619 - val_accuracy: 0.9745 - val_loss: 0.0848 - learning_rate: 0.0010\n",
      "Epoch 9/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m762s\u001b[0m 482ms/step - accuracy: 0.9795 - loss: 0.0607 - val_accuracy: 0.9712 - val_loss: 0.0908 - learning_rate: 0.0010\n",
      "Epoch 10/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m780s\u001b[0m 493ms/step - accuracy: 0.9821 - loss: 0.0568 - val_accuracy: 0.9746 - val_loss: 0.0800 - learning_rate: 2.0000e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m788s\u001b[0m 498ms/step - accuracy: 0.9816 - loss: 0.0533 - val_accuracy: 0.9738 - val_loss: 0.0801 - learning_rate: 2.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m778s\u001b[0m 491ms/step - accuracy: 0.9840 - loss: 0.0478 - val_accuracy: 0.9762 - val_loss: 0.0736 - learning_rate: 4.0000e-05\n",
      "Epoch 13/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 504ms/step - accuracy: 0.9832 - loss: 0.0533 - val_accuracy: 0.9744 - val_loss: 0.0826 - learning_rate: 4.0000e-05\n",
      "Epoch 14/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m786s\u001b[0m 496ms/step - accuracy: 0.9846 - loss: 0.0471 - val_accuracy: 0.9767 - val_loss: 0.0761 - learning_rate: 4.0000e-05\n",
      "Epoch 15/15\n",
      "\u001b[1m1583/1583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m793s\u001b[0m 501ms/step - accuracy: 0.9824 - loss: 0.0522 - val_accuracy: 0.9757 - val_loss: 0.0786 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=15,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85a9700e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL EVALUATION\n",
      "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 246ms/step - accuracy: 0.9771 - loss: 0.0760\n",
      "Validation Accuracy: 0.9760 (97.60%)\n"
     ]
    }
   ],
   "source": [
    "print(\"FINAL EVALUATION\")\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e7005d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('animals_classifier_mobilenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff2e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tkinter import Tk, filedialog\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('animals_classifier_mobilenet.h5')\n",
    "class_names = ['Animals', 'Non-Animals']\n",
    "\n",
    "def simple_predict():\n",
    "    \"\"\"Simple upload and predict without plots\"\"\"\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    \n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=\"Select an image\",\n",
    "        filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.tiff\")]\n",
    "    )\n",
    "    \n",
    "    if not file_path:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "\n",
    "        img = image.load_img(file_path, target_size=(128, 128))\n",
    "        img_array = image.img_to_array(img) / 255.0\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        \n",
    "        prediction = model.predict(img_array, verbose=0)[0][0]\n",
    "        \n",
    "        \n",
    "        predicted_class = class_names[1] if prediction > 0.5 else class_names[0]\n",
    "        confidence = prediction if predicted_class == \"Non-Animals\" else 1 - prediction\n",
    "        \n",
    "        print(f\"\\nPrediction: {predicted_class}\")\n",
    "        print(f\"Confidence: {confidence:.2%}\")\n",
    "        print(f\"File: {file_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "simple_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57741010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"animals_classifier_mobilenet.h5\", compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2214bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128, 128, 3)\n",
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "print(model.input_shape)\n",
    "print(model.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e68168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_128            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_128            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m163,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,422,081</span> (9.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,422,081\u001b[0m (9.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,097</span> (641.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,097\u001b[0m (641.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53ebccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"animals_classifier_mobilenet.h5\", compile=False)\n",
    "model.save(\"animals_classifier_mobilenet_saved.keras\")  # Save as SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15cc47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royka\\AppData\\Local\\Temp\\ipykernel_13004\\3939587060.py:9: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(include_top=False, input_tensor=input_tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "\n",
    "\n",
    "base_model = MobileNetV2(include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_tensor = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.save(\"animals_classifier_mobilenet_functional.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22b0e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royka\\AppData\\Local\\Temp\\ipykernel_13004\\47654136.py:7: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "# 1. Build functional model architecture\n",
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_tensor = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "functional_model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "# 2. Load weights from the sequential .h5 trained model\n",
    "sequential_model = load_model(\"animals_classifier_mobilenet.h5\")\n",
    "functional_model.set_weights(sequential_model.get_weights())\n",
    "\n",
    "# 3. Save as functional .keras file\n",
    "functional_model.save(\"animals_classifier_mobilenet_functional_trained.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "290f0abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_layer_1 has weights: False\n",
      "Conv1 has weights: True\n",
      "bn_Conv1 has weights: True\n",
      "Conv1_relu has weights: False\n",
      "expanded_conv_depthwise has weights: True\n",
      "expanded_conv_depthwise_BN has weights: True\n",
      "expanded_conv_depthwise_relu has weights: False\n",
      "expanded_conv_project has weights: True\n",
      "expanded_conv_project_BN has weights: True\n",
      "block_1_expand has weights: True\n",
      "block_1_expand_BN has weights: True\n",
      "block_1_expand_relu has weights: False\n",
      "block_1_pad has weights: False\n",
      "block_1_depthwise has weights: True\n",
      "block_1_depthwise_BN has weights: True\n",
      "block_1_depthwise_relu has weights: False\n",
      "block_1_project has weights: True\n",
      "block_1_project_BN has weights: True\n",
      "block_2_expand has weights: True\n",
      "block_2_expand_BN has weights: True\n",
      "block_2_expand_relu has weights: False\n",
      "block_2_depthwise has weights: True\n",
      "block_2_depthwise_BN has weights: True\n",
      "block_2_depthwise_relu has weights: False\n",
      "block_2_project has weights: True\n",
      "block_2_project_BN has weights: True\n",
      "block_2_add has weights: False\n",
      "block_3_expand has weights: True\n",
      "block_3_expand_BN has weights: True\n",
      "block_3_expand_relu has weights: False\n",
      "block_3_pad has weights: False\n",
      "block_3_depthwise has weights: True\n",
      "block_3_depthwise_BN has weights: True\n",
      "block_3_depthwise_relu has weights: False\n",
      "block_3_project has weights: True\n",
      "block_3_project_BN has weights: True\n",
      "block_4_expand has weights: True\n",
      "block_4_expand_BN has weights: True\n",
      "block_4_expand_relu has weights: False\n",
      "block_4_depthwise has weights: True\n",
      "block_4_depthwise_BN has weights: True\n",
      "block_4_depthwise_relu has weights: False\n",
      "block_4_project has weights: True\n",
      "block_4_project_BN has weights: True\n",
      "block_4_add has weights: False\n",
      "block_5_expand has weights: True\n",
      "block_5_expand_BN has weights: True\n",
      "block_5_expand_relu has weights: False\n",
      "block_5_depthwise has weights: True\n",
      "block_5_depthwise_BN has weights: True\n",
      "block_5_depthwise_relu has weights: False\n",
      "block_5_project has weights: True\n",
      "block_5_project_BN has weights: True\n",
      "block_5_add has weights: False\n",
      "block_6_expand has weights: True\n",
      "block_6_expand_BN has weights: True\n",
      "block_6_expand_relu has weights: False\n",
      "block_6_pad has weights: False\n",
      "block_6_depthwise has weights: True\n",
      "block_6_depthwise_BN has weights: True\n",
      "block_6_depthwise_relu has weights: False\n",
      "block_6_project has weights: True\n",
      "block_6_project_BN has weights: True\n",
      "block_7_expand has weights: True\n",
      "block_7_expand_BN has weights: True\n",
      "block_7_expand_relu has weights: False\n",
      "block_7_depthwise has weights: True\n",
      "block_7_depthwise_BN has weights: True\n",
      "block_7_depthwise_relu has weights: False\n",
      "block_7_project has weights: True\n",
      "block_7_project_BN has weights: True\n",
      "block_7_add has weights: False\n",
      "block_8_expand has weights: True\n",
      "block_8_expand_BN has weights: True\n",
      "block_8_expand_relu has weights: False\n",
      "block_8_depthwise has weights: True\n",
      "block_8_depthwise_BN has weights: True\n",
      "block_8_depthwise_relu has weights: False\n",
      "block_8_project has weights: True\n",
      "block_8_project_BN has weights: True\n",
      "block_8_add has weights: False\n",
      "block_9_expand has weights: True\n",
      "block_9_expand_BN has weights: True\n",
      "block_9_expand_relu has weights: False\n",
      "block_9_depthwise has weights: True\n",
      "block_9_depthwise_BN has weights: True\n",
      "block_9_depthwise_relu has weights: False\n",
      "block_9_project has weights: True\n",
      "block_9_project_BN has weights: True\n",
      "block_9_add has weights: False\n",
      "block_10_expand has weights: True\n",
      "block_10_expand_BN has weights: True\n",
      "block_10_expand_relu has weights: False\n",
      "block_10_depthwise has weights: True\n",
      "block_10_depthwise_BN has weights: True\n",
      "block_10_depthwise_relu has weights: False\n",
      "block_10_project has weights: True\n",
      "block_10_project_BN has weights: True\n",
      "block_11_expand has weights: True\n",
      "block_11_expand_BN has weights: True\n",
      "block_11_expand_relu has weights: False\n",
      "block_11_depthwise has weights: True\n",
      "block_11_depthwise_BN has weights: True\n",
      "block_11_depthwise_relu has weights: False\n",
      "block_11_project has weights: True\n",
      "block_11_project_BN has weights: True\n",
      "block_11_add has weights: False\n",
      "block_12_expand has weights: True\n",
      "block_12_expand_BN has weights: True\n",
      "block_12_expand_relu has weights: False\n",
      "block_12_depthwise has weights: True\n",
      "block_12_depthwise_BN has weights: True\n",
      "block_12_depthwise_relu has weights: False\n",
      "block_12_project has weights: True\n",
      "block_12_project_BN has weights: True\n",
      "block_12_add has weights: False\n",
      "block_13_expand has weights: True\n",
      "block_13_expand_BN has weights: True\n",
      "block_13_expand_relu has weights: False\n",
      "block_13_pad has weights: False\n",
      "block_13_depthwise has weights: True\n",
      "block_13_depthwise_BN has weights: True\n",
      "block_13_depthwise_relu has weights: False\n",
      "block_13_project has weights: True\n",
      "block_13_project_BN has weights: True\n",
      "block_14_expand has weights: True\n",
      "block_14_expand_BN has weights: True\n",
      "block_14_expand_relu has weights: False\n",
      "block_14_depthwise has weights: True\n",
      "block_14_depthwise_BN has weights: True\n",
      "block_14_depthwise_relu has weights: False\n",
      "block_14_project has weights: True\n",
      "block_14_project_BN has weights: True\n",
      "block_14_add has weights: False\n",
      "block_15_expand has weights: True\n",
      "block_15_expand_BN has weights: True\n",
      "block_15_expand_relu has weights: False\n",
      "block_15_depthwise has weights: True\n",
      "block_15_depthwise_BN has weights: True\n",
      "block_15_depthwise_relu has weights: False\n",
      "block_15_project has weights: True\n",
      "block_15_project_BN has weights: True\n",
      "block_15_add has weights: False\n",
      "block_16_expand has weights: True\n",
      "block_16_expand_BN has weights: True\n",
      "block_16_expand_relu has weights: False\n",
      "block_16_depthwise has weights: True\n",
      "block_16_depthwise_BN has weights: True\n",
      "block_16_depthwise_relu has weights: False\n",
      "block_16_project has weights: True\n",
      "block_16_project_BN has weights: True\n",
      "Conv_1 has weights: True\n",
      "Conv_1_bn has weights: True\n",
      "out_relu has weights: False\n",
      "global_average_pooling2d_1 has weights: False\n",
      "dense_2 has weights: True\n",
      "dropout_1 has weights: False\n",
      "dense_3 has weights: True\n"
     ]
    }
   ],
   "source": [
    "for layer in functional_model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(layer.name, \"has weights:\", len(weights) > 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
