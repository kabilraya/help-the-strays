{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e78aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from train_model import NaiveBayesImplementation, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed051f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Dataset/Caption Data/stray_animal_captions_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec1709f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=[\"Caption\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc5c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category'] = df['Category'].replace({\n",
    "    'Illegal': 'Illegal Activities',\n",
    "    'Illegal Activity': 'Illegal Activities'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47adb723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('stray_animal_captions_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cbbd61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caption</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wounded animal lying on the road at Itahari. V...</td>\n",
       "      <td>Help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puppy crying in pain at Pokhara. Please help!</td>\n",
       "      <td>Help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wounded animal lying on the road at Butwal. Vo...</td>\n",
       "      <td>Help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abandoned kitten found in Itahari. Looking for...</td>\n",
       "      <td>Help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Injured stray dog spotted near Butwal. Immedia...</td>\n",
       "      <td>Help</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Caption Category\n",
       "0  Wounded animal lying on the road at Itahari. V...     Help\n",
       "1      Puppy crying in pain at Pokhara. Please help!     Help\n",
       "2  Wounded animal lying on the road at Butwal. Vo...     Help\n",
       "3  Abandoned kitten found in Itahari. Looking for...     Help\n",
       "4  Injured stray dog spotted near Butwal. Immedia...     Help"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a4b5abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Caption\"].astype(str).tolist()\n",
    "Y = df[\"Category\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2a8778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e5f0079",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = [tokenize(text) for text in X_train]\n",
    "X_test_tokenized = [tokenize(text) for text in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b86c3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = NaiveBayesImplementation(alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e71b53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X_train_tokenized,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95ff9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4188e6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.999\n",
      "Training accuracy: 0.999\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = np.mean([p == t for p, t in zip(y_pred, y_test)])\n",
    "y_train_pred = model2.predict(X_train_tokenized)\n",
    "train_accuracy = np.mean([p == t for p, t in zip(y_train_pred, y_train)])\n",
    "print(f\"Test accuracy: {test_accuracy:.3f}\")\n",
    "print(f\"Training accuracy: {train_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a651dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c39b0c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[684   0   0   0]\n",
      " [  2 483   0   0]\n",
      " [  0   0 511   0]\n",
      " [  0   0   0 514]]\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Adoption       1.00      1.00      1.00       684\n",
      "              Help       1.00      1.00      1.00       485\n",
      "Illegal Activities       1.00      1.00      1.00       511\n",
      "       Vaccination       1.00      1.00      1.00       514\n",
      "\n",
      "          accuracy                           1.00      2194\n",
      "         macro avg       1.00      1.00      1.00      2194\n",
      "      weighted avg       1.00      1.00      1.00      2194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_to_idx = {cls: i for i, cls in enumerate(model2.classes_)}\n",
    "y_test_idx = [class_to_idx[cls] for cls in y_test]\n",
    "y_pred_idx = [class_to_idx[cls] for cls in y_pred]\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_idx, y_pred_idx))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=model2.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90def97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA INTEGRITY CHECK ===\n",
      "Raw training samples: 8775\n",
      "Raw test samples: 2194\n",
      "Tokenized training samples: 8775\n",
      "Tokenized test samples: 2194\n",
      "Overlapping samples between train and test: 4\n",
      "First 5 test predictions:\n",
      "True: Adoption, Pred: Adoption\n",
      "True: Illegal Activities, Pred: Illegal Activities\n",
      "True: Vaccination, Pred: Vaccination\n",
      "True: Adoption, Pred: Adoption\n",
      "True: Adoption, Pred: Adoption\n"
     ]
    }
   ],
   "source": [
    "# Add these checks to verify no leakage\n",
    "print(\"=== DATA INTEGRITY CHECK ===\")\n",
    "print(f\"Raw training samples: {len(X_train)}\")\n",
    "print(f\"Raw test samples: {len(X_test)}\")\n",
    "print(f\"Tokenized training samples: {len(X_train_tokenized)}\")\n",
    "print(f\"Tokenized test samples: {len(X_test_tokenized)}\")\n",
    "\n",
    "# Check for overlapping content between train and test\n",
    "train_texts = set([' '.join(tokens) for tokens in X_train_tokenized])\n",
    "test_texts = set([' '.join(tokens) for tokens in X_test_tokenized])\n",
    "overlap = train_texts.intersection(test_texts)\n",
    "print(f\"Overlapping samples between train and test: {len(overlap)}\")  # Should be 0\n",
    "\n",
    "# Check if your model is cheating\n",
    "print(\"First 5 test predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"True: {y_test[i]}, Pred: {y_pred[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fb9c3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly similar caption pairs (cosine > 0.9): 283\n",
      "\n",
      "Similarity: 0.930\n",
      "Caption 1: Wounded animal lying on the road at Itahari. Volunteers needed urgently!\n",
      "Caption 2: Wounded animal lying on the road at Butwal. Volunteers needed urgently!\n",
      "Category 1: Help\n",
      "Category 2: Help\n",
      "\n",
      "Similarity: 0.930\n",
      "Caption 1: Wounded animal lying on the road at Itahari. Volunteers needed urgently!\n",
      "Caption 2: Wounded animal lying on the road at Lalitpur. Volunteers needed urgently!\n",
      "Category 1: Help\n",
      "Category 2: Help\n",
      "\n",
      "Similarity: 0.929\n",
      "Caption 1: Wounded animal lying on the road at Itahari. Volunteers needed urgently!\n",
      "Caption 2: Wounded animal lying on the road at Biratnagar. Volunteers needed urgently!\n",
      "Category 1: Help\n",
      "Category 2: Help\n",
      "\n",
      "Similarity: 0.957\n",
      "Caption 1: Wounded animal lying on the road at Itahari. Volunteers needed urgently!\n",
      "Caption 2: Wounded animal lying on the road at Pokhara. Volunteers needed urgently!\n",
      "Category 1: Help\n",
      "Category 2: Help\n",
      "\n",
      "Similarity: 0.930\n",
      "Caption 1: Wounded animal lying on the road at Itahari. Volunteers needed urgently!\n",
      "Caption 2: Wounded animal lying on the road at Bhaktapur. Volunteers needed urgently!\n",
      "Category 1: Help\n",
      "Category 2: Help\n"
     ]
    }
   ],
   "source": [
    "# Check for near-duplicates (similar texts)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Check for highly similar captions\n",
    "vectorizer = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Caption'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Find highly similar pairs (cosine similarity > 0.9)\n",
    "highly_similar = []\n",
    "for i in range(len(cosine_sim)):\n",
    "    for j in range(i+1, len(cosine_sim)):\n",
    "        if cosine_sim[i][j] > 0.9:\n",
    "            highly_similar.append((i, j, cosine_sim[i][j]))\n",
    "\n",
    "print(f\"Highly similar caption pairs (cosine > 0.9): {len(highly_similar)}\")\n",
    "\n",
    "# Show some examples\n",
    "for i, j, sim in highly_similar[:5]:\n",
    "    print(f\"\\nSimilarity: {sim:.3f}\")\n",
    "    print(f\"Caption 1: {df.iloc[i]['Caption']}\")\n",
    "    print(f\"Caption 2: {df.iloc[j]['Caption']}\")\n",
    "    print(f\"Category 1: {df.iloc[i]['Category']}\")\n",
    "    print(f\"Category 2: {df.iloc[j]['Category']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31f4b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"naive_bayes_model.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a8f390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77d5f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"naive_bayes_model.json\", \"r\") as f:\n",
    "    loaded_model = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "675f5620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_priors = loaded_model[\"class_priors_log\"]\n",
    "token_likelihoods = loaded_model[\"likelihoods_log\"]\n",
    "vocab = loaded_model[\"vocab\"]\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02cc4582",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = {\n",
    "    \"a\",\"an\",\"the\",\"and\",\"or\",\"if\",\"in\",\"on\",\"of\",\"for\",\"to\",\"from\",\"is\",\"are\",\"was\",\"were\",\n",
    "    \"be\",\"been\",\"being\",\"it\",\"its\",\"this\",\"that\",\"these\",\"those\",\"as\",\"at\",\"by\",\"with\",\"but\",\n",
    "    \"about\",\"into\",\"over\",\"after\",\"before\",\"while\",\"so\",\"no\",\"not\",\"too\",\"very\",\"can\",\"cannot\",\n",
    "    \"we\",\"you\",\"your\",\"yours\",\"our\",\"ours\",\"they\",\"them\",\"their\",\"theirs\",\"he\",\"she\",\"his\",\"her\",\n",
    "    \"i\",\"me\",\"my\",\"mine\",\"do\",\"does\",\"did\",\"doing\",\"have\",\"has\",\"had\",\"having\",\"will\",\"would\",\n",
    "    \"should\",\"could\",\"may\",\"might\",\"also\",\"than\",\"then\",\"there\",\"here\",\"up\",\"down\",\"out\",\n",
    "    \"just\",\"like\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7137f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
    "    text = re.sub(r\"[@#]\\w+\", \" \", text)\n",
    "    tokens = re.findall(r\"[a-z]+\", text)\n",
    "    return [t for t in tokens if t not in STOPWORDS and len(t) > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b9cae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    tokens = tokenize(text)\n",
    "    scores = {}\n",
    "    \n",
    "    for cls in class_priors:\n",
    "        scores[cls] = class_priors[cls]\n",
    "        \n",
    "        for token in tokens:\n",
    "            if token in vocab:  \n",
    "                word_index = vocab[token]  \n",
    "                scores[cls] += token_likelihoods[cls][word_index]  \n",
    "            else:\n",
    "               \n",
    "                scores[cls] += math.log(1e-6)  \n",
    "    \n",
    "    return max(scores, key=scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57eb6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"A boy fed poison to a dog\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08caeecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illegal Activities\n"
     ]
    }
   ],
   "source": [
    "print(predict(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a68302e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caption</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wounded animal lying on the road at Itahari. V...</td>\n",
       "      <td>Help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puppy crying in pain at Pokhara. Please help!</td>\n",
       "      <td>Help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wounded animal lying on the road at Butwal. Vo...</td>\n",
       "      <td>Help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abandoned kitten found in Itahari. Looking for...</td>\n",
       "      <td>Help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Injured stray dog spotted near Butwal. Immedia...</td>\n",
       "      <td>Help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>Free rabies vaccination for street dogs in Pok...</td>\n",
       "      <td>Vaccination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Urgent help needed for injured stray puppy #9996</td>\n",
       "      <td>Help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Looking to adopt a 2-month-old vaccinated kitt...</td>\n",
       "      <td>Adoption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>Local butcher illegally killed a street dog. A...</td>\n",
       "      <td>Illegal Activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>Free rabies vaccination for street dogs in Pok...</td>\n",
       "      <td>Vaccination</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Caption            Category\n",
       "0      Wounded animal lying on the road at Itahari. V...                Help\n",
       "1          Puppy crying in pain at Pokhara. Please help!                Help\n",
       "2      Wounded animal lying on the road at Butwal. Vo...                Help\n",
       "3      Abandoned kitten found in Itahari. Looking for...                Help\n",
       "4      Injured stray dog spotted near Butwal. Immedia...                Help\n",
       "...                                                  ...                 ...\n",
       "19995  Free rabies vaccination for street dogs in Pok...         Vaccination\n",
       "19996   Urgent help needed for injured stray puppy #9996                Help\n",
       "19997  Looking to adopt a 2-month-old vaccinated kitt...            Adoption\n",
       "19998  Local butcher illegally killed a street dog. A...  Illegal Activities\n",
       "19999  Free rabies vaccination for street dogs in Pok...         Vaccination\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca42c977",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Check if your training data is imbalanced\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m Counter(\u001b[43my_train\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass distribution in training data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m, count \u001b[38;5;129;01min\u001b[39;00m class_counts\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Check if your training data is imbalanced\n",
    "class_counts = Counter(y_train)\n",
    "print(\"Class distribution in training data:\")\n",
    "for cls, count in class_counts.items():\n",
    "    print(f\"{cls}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeebe8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
